{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d1352a-b90d-4228-bc0f-ef48b4f4b7e8",
   "metadata": {},
   "source": [
    "# Yolov7 transfer learning - hard hat dataset (200 samples / 70-20-10)\n",
    "The yoloV7 repo is located here: https://github.com/WongKinYiu/yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c545a-0976-4dde-8419-4f5d10617c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt # Install the necessary packages this way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e77ddb-9da2-4f36-bd18-f7a31ffdf0a1",
   "metadata": {},
   "source": [
    "# Training on custom data\n",
    "Details on settings changes can be found under: \n",
    "https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c26067-8cf1-4e2c-b5c6-5b2c1677d9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34deba3c-f1d0-423d-ab67-4d9ffa635785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potentially download a pretrained model\n",
    "# !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527900f-0ed2-495e-b7d2-bfd660fb9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if graphic card works\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ad424d-c6c4-4069-b15f-934031af594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ e50f20b torch 2.0.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7940.125MB)\n",
      "\n",
      "Namespace(weights='MachineLearning_Python/yolo_v7/yolov7_training.pt', cfg='', data='ds_hard_hat/data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=10, batch_size=8, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=8)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/utils/google_utils.py\", line 30, in attempt_download\n",
      "    assets = [x['name'] for x in response['assets']]  # release assets\n",
      "                                 ~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'assets'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/train.py\", line 731, in <module>\n",
      "    kick_off_training(opt)\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/train.py\", line 577, in kick_off_training\n",
      "    train(hyp, opt, device, tb_writer)\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/train.py\", line 86, in train\n",
      "    attempt_download(weights)  # download if not found locally\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/utils/google_utils.py\", line 35, in attempt_download\n",
      "    tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# call training via this command...\n",
    "!python train.py --batch 8 --epochs 10 --data 'ds_hard_hat/data.yaml' --weights 'MachineLearning_Python/yolo_v7/yolov7_training.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63001e-2da8-41cb-8d0b-548358fdc6c9",
   "metadata": {},
   "source": [
    "# Evaluation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13966e6-ebe1-4944-814e-9a4d5e270716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['runs/train/exp/weights/best.pt'], source='ds_hard_hat/test/images', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
      "YOLOR ðŸš€ e50f20b torch 2.0.1 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 7940.125MB)\n",
      "\n",
      "Checking file:  runs/train/exp/weights/best.pt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/utils/google_utils.py\", line 30, in attempt_download\n",
      "    assets = [x['name'] for x in response['assets']]  # release assets\n",
      "                                 ~~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'assets'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/detect.py\", line 196, in <module>\n",
      "    detect()\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/detect.py\", line 34, in detect\n",
      "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/models/experimental.py\", line 251, in attempt_load\n",
      "    attempt_download(w)\n",
      "  File \"/home/matthias/workspace/Coding/ML_gh_repo_personal/MachineLearning_Python/yolo_v7/utils/google_utils.py\", line 35, in attempt_download\n",
      "    tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights 'runs/train/exp/weights/best.pt' --conf 0.1 --source 'ds_hard_hat/test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6ab90-f22b-422e-9252-b14a8813b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "i = 0\n",
    "limit = 10000 # max images to print\n",
    "for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n",
    "    if i < limit:\n",
    "      display(Image(filename=imageName))\n",
    "      print(\"\\n\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2d818-a621-4e08-acfd-d3a52ab952eb",
   "metadata": {},
   "source": [
    "# Reparameterize for Inference\n",
    "https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831c8bd-3719-4f09-bcfa-8a4401987473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Deploy Model on Roboflow\n",
    "# \n",
    "# Once you have finished training your YOLOv7 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/content/runs/train/exp/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
    "\n",
    "# # Deploy Your Model to the Edge\n",
    "# \n",
    "# In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n",
    "# \n",
    "# With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n",
    "# \n",
    "# For example, to install Inference on a device with an NVIDIA GPU, we can use:\n",
    "# \n",
    "# ```\n",
    "# docker pull roboflow/roboflow-inference-server-gpu\n",
    "# ```\n",
    "# \n",
    "# Then we can run inference via HTTP:\n",
    "# \n",
    "# ```python\n",
    "# import requests\n",
    "# \n",
    "# workspace_id = \"\"\n",
    "# model_id = \"\"\n",
    "# image_url = \"\"\n",
    "# confidence = 0.75\n",
    "# api_key = \"\"\n",
    "# iou_threshold = 0.5\n",
    "# \n",
    "# infer_payload = {\n",
    "#     \"image\": {\n",
    "#         \"type\": \"url\",\n",
    "#         \"value\": image_url,\n",
    "#     },ep\n",
    "#     \"confidence\": confidence,\n",
    "#     \"iou_threshold\": iou_threshold,\n",
    "#     \"api_key\": api_key,\n",
    "# }\n",
    "# res = requests.post(\n",
    "#     f\"http://localhost:9001/{workspace_id}/{model_id}\",\n",
    "#     json=infer_object_detection_payload,\n",
    "# )\n",
    "# \n",
    "# predictions = res.json()\n",
    "# ```\n",
    "# \n",
    "# Above, set your Roboflow workspace ID, model ID, and API key.\n",
    "# \n",
    "# - [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n",
    "# - [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n",
    "# \n",
    "# Also, set the URL of an image on which you want to run inference. This can be a local file.\n",
    "# \n",
    "# _To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._\n",
    "\n",
    "# # Next sts\n",
    "# \n",
    "# Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
